# 目标
- 高吞吐量
- 优雅地处理积压
- 低延时
- 分布式
- 故障转移

# 持久化方案设计
- 使用文件系统缓存代替应用进程内管理缓存，优点
	- 缓存不用参与垃圾回收（kafka使用java编写）
	- 应用重启，缓存不受影响，无须预热
	- 业务代码变得简单，维护缓存一致性的任务交给了操作系统处理
- 使用LSM代替B树，优点
	- 读与写相互独立，不阻塞对方
	- 读写时间近乎是常量，不受数据集大小影响，与数据集大小解耦
	- 消息可以保存长时间(性能不受数据集大小影响)
- 分组消息、批处理
	- 分组可以将多个消息组成一个大消息。形成大的网络包、大块的磁盘顺序操作、连续的内存。
- 生产者、代理商、消费者使用一样的消息格式
	- 同一消息无需应用内转换，就可以减少内存拷贝
		> 从文件传输数据到套接字的路径
		> - 系统从文件系统中读取数据到内核空间中的页缓存(pagecache)
		> - 应用从内核空间中拷贝数据到用户空间
		> - 应用回写数据到内核空间的套接字缓存(socket buffer)
		> - 系统从套接字缓存拷贝数据到网卡缓存
		> 
		> 如果不用应用内转换，就可以使用系统调用sendfile，直接从页缓存发送到网卡缓存中，上面只需头尾两步。
- 批量消息压缩
	- 减轻了网络宽带负担。批量消息一起压缩比单个消息压缩更高效

# 生产者设计
- 生产者直接发送消息到目标分区的领导者所在的代理节点，减去路由查询的消耗。任何节点都可回答路由元信息的请求
- 由客户端控制消息发送到哪个分区，例如随机或对某个字段哈希。这种设计允许消费端的局部敏感处理。
- 异步发送。可实现批量发送的目的。

# 消费者设计
- 消费者向分区领导者所在节点请求消息，并指定从消息队列中的某个偏移量开始取回一批消息。
- 使用传统的推拉模式：生产者推消息到代理商，消费者从代理商拉消息。
	> 推模式和拉模式的优缺点
	> - 推模式容易导致消费者过载。(可以采用退却协议(backoff)来解决这个问题，但实现起来比较棘手)。 
	> - 拉模式中，消费者可以决定最佳的消息批量大小而且不会引入不必要的延迟。推模式中，代理商必须决定是立马发送新到的消息还是等待够满足条件的批量消息才发送，前者失去缓存再批量发送的优点，后者引入不必要的延迟并且需要了解消费者情况才不会让消费者过载。
	> - 拉模式的不足是，当代理商没有数据时，会导致忙等，可通过长轮询解决。


	> 保存-转发(store-and-forward)消费模式
	> 生产者写入本地存储，消费者向代理商取消息时，代理商再向生产者取消息，然后返回给消费者。
	> 这种模式的缺点是：当有数千个生产者时，就要操作数千块磁盘，这并没有提高可靠性并且成为一个恶梦(任何一个磁盘坏了怎么处理)。

- 已消费情况的记录
	传统消息队列内部的数据结构是很难水平扩展的，缺点：
	- 当消息被确认消费时需要立即删除以便节省存储资源
	- 一条消息会有多种状态（已推送、已确认），状态数据大，处理起来有很多细节要考虑，麻烦（推送后一直没确认该怎么处理）
	
	kafka将一个topic划分为一系列分区，分区内的消息是完全有序的。一个分区在任何时刻，对于同一组内的消费者们，只能有一个去消费(但一个分区可以有多个消费者组同时进行消费)。这样，消费者在分区中的位置（已消费消息的状态数据）就只是一个整数，并且这个位置可以由消费者指定，优点：
	- 消费确认后无须立即删除（因为内部数据结构是可水平扩展的，有足够多的存储空间），消费者可以从新消费。
	- 记录已消费消息的状态数据非常小，确认消费变得非常直观容易

- 允许静态的成员关系
	动态的成员关系会引起大概率的任务重新分配
	
# 消息投递语义
> 投递语义
> - 最多一次: 信息可能会丢失，但永远不会重新交付。
> - 至少一次: 信息永远不会丢失，但可能被重新投递。
> - 正好一次: 每条信息只传递一次，而且只有一次。
>
> 这可以分解成两个问题：发布消息的持久性保证和消费消息时的保证。

- 发布消息的持久性保证
	生产者可以自主控制，是等到消息提交完成（所有同步中的节点都已持久化了该消息，只有提交完成的消息发会发给消费者），还是使用异步发布，还是只等分区领导者响应就够了（不用等其它跟从者节点确认）。不同方式对应不同的投递语义。
	- 最多一次。生产者发布消息后，不等待确认响应（对延时敏感时常用）。
	- 至少一次。生和者没有收到确认响应时，须要重发(kafka版本 < 0.11.0.0的话，重发可能会导致消息重复；之后的版本使用生产者ID以及消息ID进行去重)
	- 正好一次。生产者使用事务向一个或多个主题发布消息，要么完全成功，要么没有一个成功

- 消费消息的保证
	消费者有多种提交已消费位置的选项。不同方式对应不同的投递语义。
	- 最多一次。消费者获取到消息然后马上提交位置，接着才进行消息处理。这样，如果消费者处理这批消息的过程中崩溃了，后续接手的消费者就会从已提交的位置开始消费，而不管那批前一消费者打算处理的消息。
	- 至少一次。消费者获取消息，然后处理，完成后提交位置。如果处理完后提交位置失败，后续接手的消费者就会重新消费前一消费者处理完却没有成功提交的消息。
	- 正好一次。
		- 流处理时（从一个topic获取消息，然后把处理结果发布到另一个topic），可以使用事务，因为消费者在分区中的位置是以消息的方式记录在topic里的，所以可以在发布消息时使用事务同时提交消费位置。
		- 与外部系统交互时（处理结果发布到外部系统），外部系统需要配合才能完成，消费者位置必须像输出结果一样保存。
			- 使用二步提交。先保存结果，再保存消费位置
			- 把位置放进结果里（断点续传时，从外部系统获取位置）。

# 备份集
Kafka提供的保证是，只要至少有一个同步的副本活着，那么已确认提交完成的消息就不会丢失，在任何时候都是如此。

Kafka在节点发生故障的情况下仍然可用（在经过短暂的故障转移期后），但在网络分区的情况下可能无法继续使用。
kafka复制topic里的每一个分区到多个节点，以达到故障转移的目的（节点个数可配置，备份集个数配置可细化到topic这一级）。

分区是备份的最小单元，一个topic可配置为多个分区组成，每个分区在kafka里有一个领导者节点和0个或多个跟随者节点。分区的所有读写操作都发生在领导者节点。分区的个数会远多于节点的个数，所以分区领导者角色们会均匀地散落在节点中。

跟随者节点从领导者节点复制消息时，与普通的消费者消费的机制一样（优点：可以使用批量获取特性）。

领导者角色负责维护一个同步中的节点集，如果一个跟随者节点死亡、被卡住或落后（定义由配置选项控制），领导者将把它从同步中的节点集中删除。
> 同步中的定义
> - 节点必须能够与zookeeper通信
> - 如果是一个跟随者节点，不能与领导者节点落后太多（定义由配置选项控制）
> 
> 满足上述两个条件的节点，kafka称之为"同步中"，不使用“存活”和“失败”这种表述不够清楚的术语。

kafka只处理“失败/恢复”的分布式问题，不处理“拜占庭”式的分布式问题（节点产生任意的或恶意的响应）。