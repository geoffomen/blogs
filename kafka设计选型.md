# 目标
- 高吞吐量
- 优雅地处理积压
- 低延时
- 分布式
- 故障转移

# 持久化方案设计
- 使用文件系统缓存代替应用进程内管理缓存，优点
	- 缓存不用参与垃圾回收（kafka使用java编写）
	- 应用重启，缓存不受影响，无须预热
	- 业务代码变得简单，维护缓存一致性的任务交给了操作系统处理
- 使用LSM代替B树，优点
	- 读与写相互独立，不阻塞对方
	- 读写时间近乎是常量，不受数据集大小影响，与数据集大小解耦
	- 消息可以保存长时间(性能不受数据集大小影响)
- 分组消息、批处理
	- 分组可以将多个消息组成一个大消息。形成大的网络包、大块的磁盘顺序操作、连续的内存。
- 生产者、代理商、消费者使用一样的消息格式
	- 同一消息无需应用内转换，就可以减少内存拷贝
		> 从文件传输数据到套接字的路径
		> - 系统从文件系统中读取数据到内核空间中的页缓存(pagecache)
		> - 应用从内核空间中拷贝数据到用户空间
		> - 应用回写数据到内核空间的套接字缓存(socket buffer)
		> - 系统从套接字缓存拷贝数据到网卡缓存
		> 
		> 如果不用应用内转换，就可以使用系统调用sendfile，直接从页缓存发送到网卡缓存中，上面只需头尾两步。
- 批量消息压缩
	- 减轻了网络宽带负担。批量消息一起压缩比单个消息压缩更高效

# 生产者设计
- 生产者直接发送消息到目标分区的领导者所在的代理节点，减去路由查询的消耗。任何节点都可回答路由元信息的请求
- 由客户端控制消息发送到哪个分区，例如随机或对某个字段哈希。这种设计允许消费端的局部敏感处理。
- 异步发送。可实现批量发送的目的。

# 消费者设计
- 消费者向分区领导者所在节点请求消息，并指定从消息队列中的某个偏移量开始取回一批消息。
- 使用传统的推拉模式：生产者推消息到代理商，消费者从代理商拉消息。
	> 推模式和拉模式的优缺点
	> - 推模式容易导致消费者过载。(可以采用退却协议(backoff)来解决这个问题，但实现起来比较棘手)。 
	> - 拉模式中，消费者可以决定最佳的消息批量大小而且不会引入不必要的延迟。推模式中，代理商必须决定是立马发送新到的消息还是等待够满足条件的批量消息才发送，前者失去缓存再批量发送的优点，后者引入不必要的延迟并且需要了解消费者情况才不会让消费者过载。
	> - 拉模式的不足是，当代理商没有数据时，会导致忙等，可通过长轮询解决。


	> 保存-转发(store-and-forward)消费模式
	> 生产者写入本地存储，消费者向代理商取消息时，代理商再向生产者取消息，然后返回给消费者。
	> 这种模式的缺点是：当有数千个生产者时，就要操作数千块磁盘，这并没有提高可靠性并且成为一个恶梦(任何一个磁盘坏了怎么处理)。

- 已消费情况的记录
	传统消息队列内部的数据结构是很难水平扩展的，缺点：
	- 当消息被确认消费时需要立即删除以便节省存储资源
	- 一条消息会有多种状态（已推送、已确认），状态数据大，处理起来有很多细节要考虑，麻烦（推送后一直没确认该怎么处理）
	
	kafka将一个topic划分为一系列分区，分区内的消息是完全有序的。一个分区在任何时刻，对于同一组内的消费者们，只能有一个去消费(但一个分区可以有多个消费者组同时进行消费)。这样，消费者在分区中的位置（已消费消息的状态数据）就只是一个整数，并且这个位置可以由消费者指定，优点：
	- 消费确认后无须立即删除（因为内部数据结构是可水平扩展的，有足够多的存储空间），消费者可以从新消费。
	- 记录已消费消息的状态数据非常小，确认消费变得非常直观容易

- 允许静态的成员关系
	动态的成员关系会引起大概率的任务重新分配
	
# 消息投递语义
> 投递语义
> - 最多一次: 信息可能会丢失，但永远不会重新交付。
> - 至少一次: 信息永远不会丢失，但可能被重新投递。
> - 正好一次: 每条信息只传递一次，而且只有一次。
>
> 这可以分解成两个问题：发布消息的持久性保证和消费消息时的保证。

- 发布消息的持久性保证
	生产者可以自主控制，是等到消息提交完成（所有同步中的节点(ISR)都已持久化了该消息），还是使用异步发布，还是只等分区领导者响应就够了。一般只有提交完成的消息发才会发给消费者，但是生产者可以设置为不需要严格的确认，这时生产者发布的消息可以直接提交并被消费，即使消息备份到同步中的节点的个数少于topic设置的最低节点数(甚至只有领导者节点保存了也行)。不同方式对应不同的投递语义。
	- 最多一次。生产者发布消息后，不等待确认响应（对延时敏感时常用）。
	- 至少一次。生和者没有收到确认响应时，须要重发(kafka版本 < 0.11.0.0的话，重发可能会导致消息重复；之后的版本使用生产者ID以及消息ID进行去重)
	- 正好一次。生产者使用事务向一个或多个主题发布消息，要么完全成功，要么没有一个成功。或者由代理商进行消息去重(基于目前实现(根据生产者会话ID+消息在分区内的序列号去重)，不能跨分区跨会话)。

- 消费消息的保证
	消费者有多种提交已消费位置的选项。不同方式对应不同的投递语义。
	- 最多一次。消费者获取到消息然后马上提交位置，接着才进行消息处理。这样，如果消费者处理这批消息的过程中崩溃了，后续接手的消费者就会从已提交的位置开始消费，而不管那批前一消费者打算处理的消息。
	- 至少一次。消费者获取消息，然后处理，完成后提交位置。如果处理完后提交位置失败，后续接手的消费者就会重新消费前一消费者处理完却没有成功提交的消息。
	- 正好一次。
		- 流处理时（从一个topic获取消息，然后把处理结果发布到另一个topic），可以使用事务，因为消费者在分区中的位置是以消息的方式记录在topic里的，所以可以在发布消息时使用事务同时提交消费位置。
		- 与外部系统交互时（处理结果发布到外部系统），外部系统需要配合才能完成，消费者位置必须像输出结果一样保存。
			- 使用二步提交。先保存结果，再保存消费位置
			- 把位置放进结果里（断点续传时，从外部系统获取位置）。

# 备份集
Kafka提供的保证是，只要至少有一个同步的副本活着，那么已确认提交完成的消息就不会丢失，在任何时候都是如此。

Kafka在节点发生故障的情况下仍然可用（在经过短暂的故障转移期后），但在网络分区的情况下可能无法继续使用。
kafka复制topic里的每一个分区的log到多个节点，以达到故障转移的目的（节点个数可配置，备份集个数配置可细化到topic这一级）。

分区是备份的最小单元，一个topic可配置为多个分区组成，每个分区在kafka里有一个领导者节点和0个或多个跟随者节点。分区的所有读写操作都发生在领导者节点。分区的个数会远多于节点的个数，所以分区领导者角色们会均匀地散落在节点中。

跟随者节点从领导者节点复制消息时，与普通的消费者消费的机制一样（优点：可以使用批量获取特性）。

kafka只处理“失败/恢复”的分布式问题，不处理“拜占庭”式的分布式问题（节点产生任意的或恶意的响应）。

集群可用性与操作延时的妥协
提交消息时领导者等待更多的跟随者确认，那么后续需要选举领导者时，就会有更多的适合的节点可选择，集群可忍受更多的失败节点，相应的会使操作延时变高。 策略
- 同步中备份集(ISR)
  kafka使用这个策略。领导者角色负责维护一个同步中的节点集(包含领导者在内)，如果一个跟随者节点死亡、被卡住或落后（定义由配置选项控制），领导者将把它从同步中的备份集中删除，等到跟随者重新跟上了领导者，它又会被加入到同步集中。只有这个集合内的节点可以被选举为领导者；只有这个集合内的节点都确认后，消息才能被声明为已确认(不须要等待所有跟随者都确认)。
    - 集群可用性更高。可以忍受更多的失败节点，假如有f+1个备份集，kafka可以忍受其中f个节点失败而不会丢失已提交的消息(只要还有一个节点在同步中)。(不需要多数票)。
    - 更高的吞吐量，更少的磁盘要求(相比多数票方案，想要忍受相同的失败节点数，多数票方案需要更多的节点)。
    - 不需要节点崩溃恢复后数据保持不变。这样不用每个消息都刷盘，吞吐量也得到提高。(不少备份同步算法都是假设或要求节点崩溃后数据不受影响，但实际上磁盘错误会导致数据丢失，即使磁盘错误不会导致数据丢失，每条消息都需要刷盘会影响性能)
    - 延时较高(相比多数票方案，想要忍受相同的失败节点数条件下)。
- 基于多数票(majority-vote-based)
  确认提交与选举领导者都使用多数票。
  - 优点是，集群的延迟取决于速度比较快的跟随者节点。即是只要等到法定人数的节点就可以了，那些比较慢的节点不须理会。
  - 缺点是，不需要太多的失败节点就可以让你没有可选的领导者节点(如果选举不了领导者那么集群就不可用)。
  - 吞吐量变低，需要更多节点。这可能就是为什么基于多数票算法更多出现在“共享集群配置“系统中，如ZooKeeper，但在主数据存储中却不太常见。

为了保证集群能忍受多个节点失败，这两种策略都要求确认节点数达到法定人数。

> 法定人数
> 使 “确认提交所需节点集合	” 与 “选举领导者所需节点集合” (两集合内的节点是随机的)有一个交集的节点的个数称为法定人数。例如，有 2f+1 个结点(f为自然数)，确认提交需要 f+1 个节点，选举领导需要 f+1 个节点，这样只要不超过 f 个节点失败，就能选出一个与旧领导者拥有相同数据的新领导者，这个 f+1 就是法定人数。

> 同步中的定义
> - 节点必须能够与zookeeper通信
> - 如果是一个跟随者节点，不能与领导者节点落后太多（定义由配置选项控制）
> 
> 满足上述两个条件的节点，kafka称之为"同步中"，不使用“存活”和“失败”这种表述不够清楚的术语。

不干净的选举
当一个分区内的所有备份集都失败时，重新选举领导者时有两种策略：
- 等待同步集中的某一个节点恢复，把它选举为领导者。坏处是
	- 等待时间长，需要一直等待同步集中的某一个节点起来
	- 可能会永久不可用，如果同步集内的所有节点的所有数据都丢失的话
- 选择第一个恢复的备份集节点(不在同步集中)作为领导者。坏处是
	- 这个节点不一定拥有最新的已提交的消息。

可用性和持久性保证
生产者发布消息时，可以选择如何等待消息被确认，-1(等待同步集中所有节点确认)，0(不需要等待确认)，1(只需领导者确认即可)。如果设置不当，即使消息被确认了也会出现丢失的情况，例如，生产者选择了-1等待同步集中所有节点确认，不巧同步集中所有节点都失败了，重新选举时选出一个不在同步集中的节点做领导者。所以，为了保证持久性，需要设置
	- 禁用不干净的选举
	- 设置最低的同步集中的节点数。

# 参考资料
[Apache Kafka ](https://kafka.apache.org/documentation/#majordesignelements)